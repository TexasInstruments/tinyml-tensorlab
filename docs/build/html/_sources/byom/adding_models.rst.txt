===========================
Adding Custom Models
===========================

This guide explains how to add your own neural network architectures
to Tiny ML Tensorlab's model zoo.

Overview
--------

You can extend the model zoo with custom architectures that:

* Fit your specific accuracy/size requirements
* Implement novel layer combinations
* Target specific hardware constraints

Model Definition Structure
--------------------------

Models are defined in the TinyVerse repository using PyTorch:

.. code-block:: text

   tinyml-tinyverse/
   └── tinyml_tinyverse/
       └── common/
           └── models/
               ├── generic_model_spec.py    # Base class
               ├── generic_timeseries.py    # Time series models
               └── your_custom_model.py     # Your model

Base Class: GenericModelWithSpec
--------------------------------

All models inherit from ``GenericModelWithSpec``:

.. code-block:: python

   from tinyml_tinyverse.common.models.generic_model_spec import GenericModelWithSpec
   from tinyml_tinyverse.common.utils import py_utils

   class MY_CUSTOM_MODEL(GenericModelWithSpec):
       def __init__(self, config, input_features=128, variables=1, num_classes=3):
           super().__init__(
               config,
               input_features=input_features,
               variables=variables,
               num_classes=num_classes
           )
           self.model_spec = self.gen_model_spec()
           self._init_model_from_spec(self.model_spec)

       def gen_model_spec(self):
           """Define model architecture."""
           layers = py_utils.DictPlus()

           # Add layers here

           return dict(model_spec=layers)

Layer Types
-----------

Available layer types for model specification:

**Convolutional Layers:**

.. code-block:: python

   # Standard convolution
   layers += {'conv1': dict(
       type='ConvBNReLULayer',
       in_channels=self.variables,
       out_channels=8,
       kernel_size=(5, 1),
       stride=(1, 1),
       padding=(2, 0)
   )}

   # Depthwise convolution
   layers += {'dwconv': dict(
       type='DWConvBNReLULayer',
       in_channels=8,
       out_channels=8,
       kernel_size=(3, 1),
       stride=(1, 1)
   )}

   # Pointwise convolution
   layers += {'pwconv': dict(
       type='PWConvBNReLULayer',
       in_channels=8,
       out_channels=16
   )}

**Pooling Layers:**

.. code-block:: python

   # Max pooling
   layers += {'pool1': dict(
       type='MaxPoolLayer',
       kernel_size=(2, 1),
       stride=(2, 1)
   )}

   # Average pooling
   layers += {'avgpool': dict(
       type='AvgPoolLayer',
       kernel_size=(4, 1),
       stride=(4, 1)
   )}

   # Global average pooling
   layers += {'gap': dict(
       type='GlobalAvgPoolLayer'
   )}

**Fully Connected Layers:**

.. code-block:: python

   # Reshape for FC
   layers += {'flatten': dict(
       type='ReshapeLayer',
       ndim=2
   )}

   # Linear layer
   layers += {'fc': dict(
       type='LinearLayer',
       in_features=64,
       out_features=self.num_classes
   )}

**Other Layers:**

.. code-block:: python

   # Batch normalization
   layers += {'bn': dict(
       type='BatchNormLayer',
       num_features=16
   )}

   # Dropout
   layers += {'dropout': dict(
       type='DropoutLayer',
       p=0.5
   )}

   # Activation
   layers += {'relu': dict(
       type='ReLULayer'
   )}

Complete Model Example
----------------------

A complete classification model:

.. code-block:: python

   class CLS_CUSTOM_1k(GenericModelWithSpec):
       """Custom 1k parameter classification model."""

       def __init__(self, config, input_features=128, variables=1, num_classes=3):
           super().__init__(
               config,
               input_features=input_features,
               variables=variables,
               num_classes=num_classes
           )
           self.model_spec = self.gen_model_spec()
           self._init_model_from_spec(self.model_spec)

       def gen_model_spec(self):
           layers = py_utils.DictPlus()

           # First conv: 1 input channel -> 4 output channels
           layers += {'0': dict(
               type='ConvBNReLULayer',
               in_channels=self.variables,
               out_channels=4,
               kernel_size=(5, 1),
               stride=(1, 1),
               padding=(2, 0)
           )}

           # Pooling
           layers += {'1': dict(
               type='MaxPoolLayer',
               kernel_size=(2, 1),
               stride=(2, 1)
           )}

           # Second conv
           layers += {'2': dict(
               type='ConvBNReLULayer',
               in_channels=4,
               out_channels=8,
               kernel_size=(3, 1),
               stride=(1, 1),
               padding=(1, 0)
           )}

           # Pooling
           layers += {'3': dict(
               type='MaxPoolLayer',
               kernel_size=(2, 1),
               stride=(2, 1)
           )}

           # Flatten
           layers += {'4': dict(
               type='ReshapeLayer',
               ndim=2
           )}

           # Calculate FC input size based on input_features and pooling
           fc_input = 8 * (self.input_features // 4)

           # Classifier
           layers += {'5': dict(
               type='LinearLayer',
               in_features=fc_input,
               out_features=self.num_classes
           )}

           return dict(model_spec=layers)

NPU-Compatible Model
--------------------

For NPU devices, follow these constraints:

.. code-block:: python

   class CLS_CUSTOM_NPU(GenericModelWithSpec):
       """NPU-compatible custom model."""

       def __init__(self, config, input_features=128, variables=1, num_classes=3):
           super().__init__(
               config,
               input_features=input_features,
               variables=variables,
               num_classes=num_classes
           )
           self.model_spec = self.gen_model_spec()
           self._init_model_from_spec(self.model_spec)

       def gen_model_spec(self):
           layers = py_utils.DictPlus()

           # First conv: variables must be 1, out_channels multiple of 4
           layers += {'0': dict(
               type='ConvBNReLULayer',
               in_channels=1,  # FCONV requires 1
               out_channels=4,  # Multiple of 4
               kernel_size=(5, 1),  # Height <= 7
               stride=(1, 1)
           )}

           # GCONV: all channels multiple of 4, kernel height <= 7
           layers += {'1': dict(
               type='ConvBNReLULayer',
               in_channels=4,
               out_channels=8,
               kernel_size=(5, 1),
               stride=(1, 1)
           )}

           # MaxPool: kernel <= 4x4
           layers += {'2': dict(
               type='MaxPoolLayer',
               kernel_size=(2, 1),
               stride=(2, 1)
           )}

           layers += {'3': dict(
               type='ConvBNReLULayer',
               in_channels=8,
               out_channels=16,
               kernel_size=(5, 1),
               stride=(1, 1)
           )}

           layers += {'4': dict(
               type='MaxPoolLayer',
               kernel_size=(2, 1),
               stride=(2, 1)
           )}

           layers += {'5': dict(
               type='ReshapeLayer',
               ndim=2
           )}

           # FC: in_features >= 16
           layers += {'6': dict(
               type='LinearLayer',
               in_features=16 * (self.input_features // 4),
               out_features=self.num_classes
           )}

           return dict(model_spec=layers)

Registering Your Model
----------------------

After defining the model, register it in the model registry:

**Step 1: Add to model file**

Add your class to the appropriate file in ``models/``.

**Step 2: Update __init__.py**

In ``models/__init__.py``:

.. code-block:: python

   from .your_custom_model import CLS_CUSTOM_1k, CLS_CUSTOM_NPU

   # Add to model registry
   MODEL_REGISTRY = {
       # ... existing models ...
       'CLS_CUSTOM_1k': CLS_CUSTOM_1k,
       'CLS_CUSTOM_NPU': CLS_CUSTOM_NPU,
   }

**Step 3: Test registration**

.. code-block:: python

   from tinyml_tinyverse.common.models import MODEL_REGISTRY

   # Verify model is registered
   print('CLS_CUSTOM_1k' in MODEL_REGISTRY)  # Should print True

Using Your Custom Model
-----------------------

Reference in configuration:

.. code-block:: yaml

   training:
     model_name: 'CLS_CUSTOM_1k'  # Your model name
     training_epochs: 30

Testing Your Model
------------------

Before deploying, test your model:

**Unit Test:**

.. code-block:: python

   import torch
   from your_custom_model import CLS_CUSTOM_1k

   # Create model
   config = {}  # Your config
   model = CLS_CUSTOM_1k(
       config,
       input_features=512,
       variables=1,
       num_classes=3
   )

   # Test forward pass
   x = torch.randn(1, 1, 512, 1)
   output = model(x)

   print(f"Input shape: {x.shape}")
   print(f"Output shape: {output.shape}")
   print(f"Parameters: {sum(p.numel() for p in model.parameters())}")

**Export Test:**

.. code-block:: python

   import torch.onnx

   # Export to ONNX
   torch.onnx.export(
       model,
       x,
       "custom_model.onnx",
       input_names=['input'],
       output_names=['output'],
       opset_version=11
   )

   print("ONNX export successful")

Best Practices
--------------

1. **Follow naming conventions**: Use task prefix (``CLS_``, ``AD_``, ``FCST_``)
2. **Document your model**: Add docstrings and comments
3. **Test thoroughly**: Verify shapes and parameter counts
4. **Consider NPU constraints**: If targeting NPU devices
5. **Start from existing models**: Modify rather than create from scratch

Adding Custom Feature Extractors
---------------------------------

You can add custom feature extractors to the TinyVerse repository for use
during data preprocessing. The feature extractor is added to TinyVerse and
then imported into the data loading pipeline.

**Step 1: Create the feature extractor file**

Add a new Python file in the transforms directory:

.. code-block:: text

   tinyml-tinyverse/
   └── tinyml_tinyverse/
       └── common/
           └── transforms/
               └── your_feature_extractor.py

**Step 2: Import into the data loader**

Import the feature extractor in ``common/datasets/timeseries_dataset.py`` and
use it in the data loading pipeline:

.. code-block:: python

   from tinyml_tinyverse.common.transforms.your_feature_extractor import YourFeatureExtractor

At this stage, the TinyVerse package can function independently with the new
feature extractor.

Adding New Modalities
---------------------

A modality (also referred to as an ``ai_module``) represents a distinct data
domain such as ``audio``, ``timeseries``, or ``vision``. Adding a new modality
requires changes in both tinyml-modelmaker and tinyml-tinyverse.

**ModelMaker Directory Structure**

Each modality must have three mandatory subparts: ``datasets``, ``training``,
and ``compilation``. The directory structure under
``tinyml-modelmaker/tinyml_modelmaker/ai_modules/`` is as follows:

.. code-block:: text

   tinyml_modelmaker/ai_modules/your_modality/
   ├── __init__.py              # Imports from subsequent files
   ├── constants.py             # Modality-specific constants
   ├── descriptions.py          # Human-readable descriptions
   ├── params.py                # Parameters for dataset, training, compilation
   ├── runner.py                # Core engine that runs the flow from config
   ├── datasets/
   │   └── __init__.py
   ├── training/
   │   ├── __init__.py
   │   └── tinyml_tinyverse/
   │       ├── __init__.py
   │       └── task_name.py     # e.g., classification.py, regression.py
   └── compilation/
       └── __init__.py

**Key files:**

* ``constants.py`` -- Defines constants specific to the modality.
* ``descriptions.py`` -- Provides human-readable descriptions of tasks and
  parameters.
* ``params.py`` -- Contains the parameters required for dataset, training, and
  compilation tasks from the configuration YAML file.
* ``runner.py`` -- The core engine that runs the processing flow based on the
  configuration file.

.. note::

   Unless necessary, the ``__init__.py`` files under ``datasets``, ``training``,
   and ``compilation`` can contain the same contents as other modalities such as
   ``audio`` or ``timeseries``.

**TinyVerse Changes**

An equivalent update in the tinyml-tinyverse repository is also required. Add
the corresponding folders and files as needed for any combination of
``transforms``, ``datasets``, ``models``, ``compilations``, or ``utils``.

Configuring Model Layer Parameters
-----------------------------------

You can override a model's ``__init__`` arguments at runtime using a
``model_config`` YAML file. This allows you to change parameters such as
``input_features``, ``variables``, and ``num_classes`` without modifying the
model source code.

**Creating a model_config file**

Example model_config files can be found in the ``misc/`` folder of the
tinyml-modelmaker repository. The YAML file should contain the parameters that
the model class accepts as ``__init__`` arguments.

For example, the class ``CNN_TS_GEN_BASE_13K`` (referred to by the model name
``TimeSeries_Generic_13k_t``) accepts the following arguments:

.. code-block:: python

   class CNN_TS_GEN_BASE_13K(GenericModelWithSpec):
       def __init__(self, config, input_features=512, variables=1, num_classes=2):

A corresponding ``model_config`` YAML file can override any of these arguments:

.. code-block:: yaml

   input_features: 512
   variables: 2
   num_classes: 3

**Using the model_config in your configuration**

Specify the path to the ``model_config`` file in the ``training`` section of
your project configuration YAML:

.. code-block:: yaml

   training:
     enable: True
     model_name: 'TimeSeries_Generic_13k_t'
     model_config: '/path/to/tinyml-modelmaker/misc/TimeSeries_Generic_x_t.yaml'

This will override the model's default ``__init__`` arguments with the values
specified in the ``model_config`` file. You can provide none, some, or all of
the supported arguments -- any arguments not specified will retain their default
values.

Next Steps
----------

* See :doc:`compilation_only` to compile external models
* Review :doc:`/devices/npu_guidelines` for NPU constraints
* Check :doc:`/features/quantization` for quantization support
