# Grid Stability: Understanding ModelMaker Outputs
### -Tushar Sharma, Adithya Thonse, Fasna S 
<hr>

## Overview

The Grid Stability Dataset is a multivariate dataset created by UCI Machine Learning Repository. The dataset is created by stability analysis of 4-node star system. There is 1 generation node in center and 3 consumer nodes. There are 3 parameters (Tau, P, G) for each node amounting to total 12 independent variables. There are two prediction variable for stability (numerical and categorical). The dataset obtains the power consumption, reaction time of participants & the price elasticity to predicts whether the grid will be stable or not. [Read More](https://arxiv.org/abs/1508.02217)

Independent Variable:

1. (tau1, tau2, tau3, tau4): time needed for grid participant to adjust the power generation or consumption
2. (p1, p2, p3, p4): Power consumed by the consumer or generated by producer
3. (g1, g2, g3, g4): price elasticity coefficient

<p align="center">  
    <img src="assets/four_node_start.svg" width="280" alt="Image Alt">
</p>

## Downloading the dataset

Prepare the zipped dataset by running the grid_stability python file. The script will create zipped dataset as `grid_stability_dataset.zip`. 
```bash
cd examples/grid_stability
python grid_stability.py
```
The path of this zipped dataset file is already mentioned in [configuration](config_classification_grid_stability.yaml) yaml, make sure it is same.

```yaml
dataset:
    input_data_path: 'examples/grid_stability/grid_stability_dataset.zip'
```

This zipped dataset is designed to work with TinyML ModelMaker. Run the modelmaker with the yaml [configuration](config_classification_grid_stability.yaml).

## How ModelMaker helps ?

TinyML ModelMaker is an end-to-end model development tool that provides dataset handling, model training and compilation. You can run the modelmaker for the given configuration yaml by the following command in terminal.

```bash
cd tinyml-modelmaker
run_tinyml_modelmaker.sh F28P55 examples/grid_stability/config_timeseries_grid_stability.yaml
```

ModelMaker will start by loading the dataset, train the model, test the model, compile the model. ModelMaker will create the output folder in `tinyml-modelmaker/data/projects/{dataset_name}`. For this example dataset_name is `grid_stability`. You can find the dataset name in the configuration [yaml](config_classification_grid_stability.yaml)

```yaml
dataset:
    dataset_name: grid_stability
```

The data folder structure of tinyml-modelmaker is as follows:

```
tinyml-modelmaker
|_ data
    |_ descriptions
        |_ description_timeseries.json
        |_ description_timeseries.yaml
    |_ projects
        |_ electrical_fault
        |_ grid_stability   # (dataset_name)
            |_ dataset
                |_ annotations
                |_ classes
                    |_ class0_stable
                    |_ class1_unstable
            |_ run
                |_ 20250226-132343  # (date-time)
                    |_ Res_Slice_TimeSeries_Generic_3k_t    # (model_name)
                        |_ compilation
                        |_ training
                            |_ base
                            |_ quantization
                |_ 20250227-111317
        |_ motor_fault_example_dsk
```
TinyML ModelMaker outputs extracted features, pca analysis of extracted features, model, compiled model, analysis of extracted features, test setup for testing model on device in `data/projects/grid_stability/run/date-time/model_name`. Let's look at this folder in depth.
```
|_ Res_Slice_TimeSeries_Generic_3k_t (model_name)
    |_ compilation
        |_ artifacts
            |_ mod.a
            |_ tvmgen_default.h
    |_ training
        |_ base
            |_ feat_ext_data
            |_ golden_vectors
                |_ test_vector.c
                |_ user_input_config.h
            |_ model.onnx
            |_ pca_on_feature_extracted_train_data.png
            |_ pca_on_feature_extracted_validation_data.png
        |_ quantization
            |_ feat_ext_data
            |_ golden_vectors
                |_ test_vector.c
                |_ user_input_config.h
            |_ post_training_analysis
            |_ model.onnx
            |_ pca_on_feature_extracted_train_data.png
            |_ pca_on_feature_extracted_validation_data.png
```
1. `compilation` (stores the compiled model which can be used in target device)
    1. **artifacts**
        1. **mod.a**: archive library (.a) model, it can be statically linked to your program while compiling
        2. **tvmgen_default.h** : header file to use the functions present in mod.a
2. `training` (related to extracted features, test setup for model and model)
    1. **base**
        1. feat_ext_data: stores the extracted features of dataset in NumPy (.npy)
        2. golden_vectors
            1. test_vector.c: contains test data and its output, this can be used to check if the model is working correctly in device
            2. user_input_config.h: configuration of feature extraction for ai library present in c2000ware
        3. model.onnx: onnx floating point model
        4. pca_on_feature_extracted_train_data.png: PCA analysis of extracted features. [Refer here](../how_good_is_your_feature_extraction/readme.md)
    2. **quantization**
        1. feat_ext_data: stores the extracted features of dataset in NumPy (.npy)
        2. **golden_vectors**
            1. **test_vector.c**: contains test data and its output, this can be used to check if the model is working correctly in device
            2. **user_input_config.h**: configuration of feature extraction for ai library present in c2000ware
        3. **model.onnx**: onnx fixed point model
        4. pca_on_feature_extracted_train_data.png: PCA analysis of extracted features. [Refer here](../how_good_is_your_feature_extraction/readme.md)
        5. **post_training_analysis**: Performing a quick insight on the model performance (not latency related). [Refer here](../post_training_analysis/Post_Training_Analysis.md)
3. run.json, run.yaml, status.json, status.yaml: complete list of configurations used to run the ModelMaker

## Output for Target Device

The target device has four useful file outputs by ModelMaker.
- `mod.a`: The ONNX model is compiled by tvm to get C files, which are converted into a single mod.a that can run on device.
- `tvmgen_default.h`: Mod.a exposes few APIs to interact with model which are present here. You can use these APIs in your application to run model

- `test_vector.c`: ModelMaker gives a test dataset and the expected output. You can use the model to inference this test dataset and check if the output is matching. 
- `user_input_config.h`: This configuration file has preprocessing flag definitions for the parameters used for feature extraction.

<hr>
Update history:

[14th Mar 2025]: Compatible with v1.0 of Tiny ML Modelmaker
