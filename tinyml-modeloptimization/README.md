# Tiny ML Torch Model Optimization Repository

This repository helps you to quantize (QAT) your floating point ONNX model to a model that can run optimally with TI's MCUs

An example on using this repository is present at [references](./references/)
You can follow the instructions in [readme](./references/fmnist_ti_qat_readme.md) 


---
## Contributor and Maintainer
- [Adithya Thonse](https://github.com/Adithya-Thonse)
- [Manu Mathew](https://github.com/mathmanu)
- [Ajay Jayaraj](ajayj@ti.com)
